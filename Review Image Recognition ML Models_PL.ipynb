{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a collective notes in reviewing various ML models for image recognition\n",
    "* The codes need to be tune further for a specifice project\n",
    "* Data are in the links corresponding to the models to, not in the repositories; need to download and import the data when running the models\n",
    "* Credit:\n",
    "        - https://www.kaggle.com/nafisur/nr-dogs-vs-cats-keras-cnn\n",
    "        - https://www.kaggle.com/twhitehurst3/intel-classification-keras-cnn-92-acc/\n",
    "        - https://www.kaggle.com/hortonhearsafoo/fast-ai-lesson-1/notebook\n",
    "        - https://www.kaggle.com/hortonhearsafoo/fast-ai-lesson-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "1. Import generic range of possibly required libraries\n",
    "2. Build models:\n",
    "    - Model 1: Image Scene Classification of Multiclass Kaggle;\n",
    "    - Model 2: Keras CNN Dog or Cat Classification Kaggle   \n",
    "    - Model 3: NR_dogs_vs_cats_keras_CNN Kaggle\n",
    "    - Model 4: fast.ai lesson 1 (pretrained restnet34) Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import a generic range of possibly required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import Image as pil_image\n",
    "from time import time\n",
    "from PIL import ImageDraw\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os,shutil,math,scipy,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc,ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.applications.vgg19 import VGG19,preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\n",
    "from keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "Image Scene Classification of Multiclass\n",
    "[Kaggle](https://www.kaggle.com/twhitehurst3/intel-classification-keras-cnn-92-acc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download and save the data then fill the paths\n",
    "# Data source: https://www.kaggle.com/twhitehurst3/intel-classification-keras-cnn-92-acc/data\n",
    "train_dir = '../input/seg_train/seg_train/'\n",
    "test_dir = '../input/seg_test/seg_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !\n",
    "def show_final_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('acc')\n",
    "    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,  \n",
    "    zoom_range=0.2,        \n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.3)  \n",
    "\n",
    "train_gen = augs.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size=8,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "test_gen = augs.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(model, layers, filters,name):\n",
    "    for i in range(layers):\n",
    "        model.add(SeparableConv2D(filters, (3, 3), activation='relu',name=name))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "def FCN():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x, input_shape=(150, 150, 3)))\n",
    "    ConvBlock(model, 1, 16,'block_1')\n",
    "    ConvBlock(model, 1, 32,'block_2')\n",
    "    ConvBlock(model, 1, 64,'block_3')\n",
    "    ConvBlock(model, 1, 128,'block_4')\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6,activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "model = FCN()\n",
    "model.summary()\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_weights = './base.model'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    best_model_weights,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only=False,\n",
    "    period=1\n",
    ")\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir = './logs',\n",
    "    histogram_freq=0,\n",
    "    batch_size=16,\n",
    "    write_graph=True,\n",
    "    write_grads=True,\n",
    "    write_images=False,\n",
    ")\n",
    "\n",
    "csvlogger = CSVLogger(\n",
    "    filename= \"training_csv.log\",\n",
    "    separator = \",\",\n",
    "    append = False\n",
    ")\n",
    "\n",
    "#lrsched = LearningRateScheduler(step_decay,verbose=1)\n",
    "\n",
    "reduce = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=40,\n",
    "    verbose=1, \n",
    "    mode='auto',\n",
    "    cooldown=1 \n",
    ")\n",
    "\n",
    "callbacks = [checkpoint,tensorboard,csvlogger,reduce]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=1e-4,momentum=0.99)\n",
    "opt1 = Adam(lr=2e-4)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "    \n",
    "history = model.fit_generator(\n",
    "    train_gen, \n",
    "    steps_per_epoch  = 500, \n",
    "    validation_data  = test_gen,\n",
    "    validation_steps = 500,\n",
    "    epochs = 20, \n",
    "    verbose = 1,\n",
    "    callbacks=callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_final_history(history)\n",
    "model.load_weights(best_model_weights)\n",
    "model_score = model.evaluate_generator(test_gen)\n",
    "print(\"Model Test Loss:\",model_score[0])\n",
    "print(\"Model Test Accuracy:\",model_score[1])\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save(\"model.h5\")\n",
    "print(\"Weights Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "LOG_DIR = './logs' # Here you have to put your log directory\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 8080 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Keras CNN Dog or Cat Classification\n",
    "[Kaggle](https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To download and save the data then fill the paths\n",
    "# Data source: https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification/data\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "FAST_RUN = False\n",
    "IMAGE_WIDTH=128\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3 # RGB color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"../input/train/train\")\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Total In count\n",
    "df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See sample image\n",
    "sample = random.choice(filenames)\n",
    "image = load_img(\"../input/train/train/\"+sample)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stop\n",
    "# To prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased\n",
    "earlystop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Reduction\n",
    "# We will reduce the learning rate when then accuracy not increase for 2 steps\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning Generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    \"../input/train/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"../input/train/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how the generators work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
    "example_generator = train_datagen.flow_from_dataframe(\n",
    "    example_df, \n",
    "    \"../input/train/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(0, 15):\n",
    "    plt.subplot(5, 3, i+1)\n",
    "    for X_batch, Y_batch in example_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=3 if FAST_RUN else 50\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, epochs, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, epochs, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(\"../input/test1/test1\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Testing Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    \"../input/test1/test1/\", \n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As predicted of binary classification result return probability that image likely to be a dog. \n",
    "# We will have threshold 0.5 which mean if predicted value more than 50% it is a dog and under 50% will be a cat.\n",
    "threshold = 0.5\n",
    "test_df['probability'] = predict\n",
    "test_df['category'] = np.where(test_df['probability'] > threshold, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results in graph\n",
    "test_df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See predicted result with images\n",
    "sample_test = test_df.head(18)\n",
    "sample_test.head()\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    probability = row['probability']\n",
    "    img = load_img(\"../input/test1/test1/\"+filename, target_size=IMAGE_SIZE)\n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' '(' + \"{}\".format(round(probability, 2)) + ')')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission (only for Kaggle competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_df.copy()\n",
    "submission_df['id'] = submission_df['filename'].str.split('.').str[0]\n",
    "submission_df['label'] = submission_df['category']\n",
    "submission_df.drop(['filename', 'category'], axis=1, inplace=True)\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "NR_dogs_vs_cats_keras_CNN\n",
    "[Kaggle](https://www.kaggle.com/nafisur/nr-dogs-vs-cats-keras-cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and preprocess\n",
    "- Data source:https://www.kaggle.com/kernels/scriptcontent/4285328/data\n",
    "- Image generator, to generate rotated,shifted,flipped images etc. To over come Translational invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input/dataset/dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library\n",
    "from keras.layers import Conv2D,Dropout,Dense,Flatten,MaxPooling2D,ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.losses import binary_crossentropy,categorical_crossentropy\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(64,64,3)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(ZeroPadding2D(padding=(1,1)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=binary_crossentropy,optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=train_datagen.flow_from_directory(directory='../input/dataset/dataset/training_set',target_size=(64,64),class_mode='binary')\n",
    "\n",
    "test_set=test_datagen.flow_from_directory('../input/dataset/dataset/test_set/',target_size=(64,64),class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit_generator(training_set,steps_per_epoch = 2000//32,epochs =20 ,validation_data = test_set,validation_steps = 800//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4\n",
    "fast.ai lesson 1\n",
    "[Kaggle](https://www.kaggle.com/hortonhearsafoo/fast-ai-lesson-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH is the path to your data \n",
    "# - if you use the recommended setup approaches from the lesson, you won't need to change this. \n",
    "# - sz is the size that the images will be resized to in order to ensure that the training runs quickly. \n",
    "# We'll be talking about this parameter a lot during the course. Leave it at 224 for now.\n",
    "PATH = \"../input/\"\n",
    "TMP_PATH = \"/tmp/tmp\"\n",
    "MODEL_PATH = \"/tmp/model/\"\n",
    "sz=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's important that you have a working NVidia GPU set up. \n",
    "# The programming framework used to behind the scenes to work with NVidia GPUs is called CUDA. \n",
    "# Therefore, you need to ensure the following line returns True before you proceed. \n",
    "# If you have problems with this, please check the FAQ and ask for help on the forums.\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition, NVidia provides special accelerated functions for deep learning in a package called CuDNN. \n",
    "# Although not strictly necessary, it will improve training performance significantly, and is included by default in all supported fastai configurations. \n",
    "# Therefore, if the following does not return True, you may want to look into why.\n",
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = np.array([f'train/{f}' for f in sorted(os.listdir(f'{PATH}train'))])\n",
    "labels = np.array([(0 if 'cat' in fname else 1) for fname in fnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(f'{PATH}{fnames[0]}')\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how the raw data looks like\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:4,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model 4 using pretrained resnet34 model\n",
    "[resnet34](https://github.com/KaimingHe/deep-residual-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below if you need to reset your precomputed activations\n",
    "# shutil.rmtree(f'{PATH}tmp', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evalulate a dogs vs cats model in 3 lines of code, and under 20 seconds:\n",
    "arch=resnet34\n",
    "data = ImageClassifierData.from_names_and_array(\n",
    "    path=PATH, \n",
    "    fnames=fnames, \n",
    "    y=labels, \n",
    "    classes=['dogs', 'cats'], \n",
    "    test_name='test', \n",
    "    tfms=tfms_from_model(arch, sz)\n",
    ")\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)\n",
    "learn.fit(0.01, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this model? Well, as we mentioned, prior to this competition, the state of the art was 80% accuracy. But the competition resulted in a huge jump to 98.9% accuracy, with the author of a popular deep learning library winning the competition. Extraordinarily, less than 4 years later, we can now beat that result in seconds! Even last year in this same course, our initial model had 98.3% accuracy, which is nearly double the error we're getting just a year later, and that took around 10 minutes to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing results: looking at pictures\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "\n",
    "A few correct labels at random\n",
    "A few incorrect labels at random\n",
    "The most correct labels of each class (i.e. those with highest probability that are correct)\n",
    "The most incorrect labels of each class (i.e. those with highest probability that are incorrect)\n",
    "The most uncertain labels (i.e. those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the label for a val data\n",
    "data.val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from here we know that 'cats' is label 0 and 'dogs' is label 1.\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gives prediction for validation set. Predictions are in log scale\n",
    "log_preds = learn.predict()\n",
    "log_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(log_preds, axis=1)  # from log probabilities to 0 or 1\n",
    "probs = np.exp(log_preds[:,1])        # pr(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], 4, replace=False)\n",
    "def rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=1, titles=None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_id(ds, idx): return np.array(PIL.Image.open(PATH+ds.fnames[idx]))\n",
    "\n",
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. A few correct labels at random\n",
    "plot_val_with_title(rand_by_correct(True), \"Correctly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. A few incorrect labels at random\n",
    "plot_val_with_title(rand_by_correct(False), \"Incorrectly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_by_mask(mask, mult):\n",
    "    idxs = np.where(mask)[0]\n",
    "    return idxs[np.argsort(mult * probs[idxs])[:4]]\n",
    "\n",
    "def most_by_correct(y, is_correct): \n",
    "    mult = -1 if (y==1)==is_correct else 1\n",
    "    return most_by_mask(((preds == data.val_y)==is_correct) & (data.val_y == y), mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, True), \"Most correct cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, True), \"Most correct dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, False), \"Most incorrect cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), \"Most incorrect dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(probs -0.5))[:4]\n",
    "plot_val_with_title(most_uncertain, \"Most uncertain predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a learning rate\n",
    "The learning rate determines how quickly or how slowly you want to update the weights (or parameters). \n",
    "Learning rate is one of the most difficult parameters to set, because it significantly affects model performance.\n",
    "\n",
    "The method learn.lr_find() helps you find an optimal learning rate. It uses the technique developed in the 2015 paper Cyclical Learning Rates for Training Neural Networks, where we simply keep increasing the learning rate from a very small value, until the loss stops decreasing. We can plot the learning rate across batches to see what this looks like.\n",
    "\n",
    "We first create a new learner, since we want to know how to set the learning rate for a new (untrained) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf=learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Our learn object contains an attribute sched that contains our learning rate scheduler, and has some convenient plotting functionality including this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the previous plot iteration is one iteration (or minibatch) of SGD. In one epoch there are (num_train_samples/num_iterations) of SGD.\n",
    "\n",
    "We can see the plot of loss versus learning rate to see where our loss stops decreasing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is still clearly improving at lr=1e-2 (0.01), so that's what we use. Note that the optimal learning rate can change as we train the model, so you may want to re-run this function from time to time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation\n",
    "If you try training for more epochs, you'll notice that we start to overfit, which means that our model is learning to recognize the specific images in the training set, rather than generalizing such that we also get good results on the validation set. One way to fix this is to effectively create more data, through data augmentation. This refers to randomly changing the images in ways that shouldn't impact their interpretation, such as horizontal flipping, zooming, and rotating.\n",
    "\n",
    "We can do this by passing aug_tfms (augmentation transforms) to tfms_from_model, with a list of functions to apply that randomly change the image however we wish. For photos that are largely taken from the side (e.g. most photos of dogs and cats, as opposed to photos taken from the top down, such as satellite imagery) we can use the pre-defined list of functions transforms_side_on. We can also specify random zooming of images up to specified scale by adding the max_zoom parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(resnet34, sz, aug_tfms=transforms_side_on, max_zoom=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augs():\n",
    "    data = ImageClassifierData.from_names_and_array(\n",
    "        path=PATH, \n",
    "        fnames=fnames, \n",
    "        y=labels, \n",
    "        classes=['dogs', 'cats'], \n",
    "        test_name='test', \n",
    "        tfms=tfms,\n",
    "        num_workers=1,\n",
    "        bs=2\n",
    "    )\n",
    "    x,_ = next(iter(data.aug_dl))\n",
    "    return data.trn_ds.denorm(x)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = np.stack([get_augs() for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(ims, rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data object that includes this augmentation in the transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageClassifierData.from_names_and_array(\n",
    "    path=PATH, \n",
    "    fnames=fnames, \n",
    "    y=labels, \n",
    "    classes=['dogs', 'cats'], \n",
    "    test_name='test', \n",
    "    tfms=tfms\n",
    ")\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.precompute=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default when we create a learner, it sets all but the last layer to frozen. That means that it's still only updating the weights in the last layer when we call fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 3, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is that cycle_len parameter? What we've done here is used a technique called stochastic gradient descent with restarts (SGDR), a variant of learning rate annealing, which gradually decreases the learning rate as training progresses. This is helpful because as we get closer to the optimal weights, we want to take smaller steps.\n",
    "\n",
    "However, we may find ourselves in a part of the weight space that isn't very resilient - that is, small changes to the weights may result in big changes to the loss. We want to encourage our model to find parts of the weight space that are both accurate and stable. Therefore, from time to time we increase the learning rate (this is the 'restarts' in 'SGDR'), which will force the model to jump to a different part of the weight space if the current area is \"spikey\". Here's a picture of how that might look if we reset the learning rates 3 times (in this paper they call it a \"cyclic LR schedule\"):\n",
    "\n",
    "(From the paper Snapshot Ensembles).\n",
    "\n",
    "The number of epochs between resetting the learning rate is set by cycle_len, and the number of times this happens is refered to as the number of cycles, and is what we're actually passing as the 2nd parameter to fit(). So here's what our actual learning rates looked like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Our validation loss isn't improving much, so there's probably no point further training the last layer on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "*so we can load it again later without training it from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('224_lastlayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('224_lastlayer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning and differential learning rate annealing\n",
    "Now that we have a good final layer trained, we can try fine-tuning the other layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To tell the learner that we want to unfreeze the remaining layers, just call (surprise surprise!) unfreeze():\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the other layers have already been trained to recognize imagenet photos (whereas our final layers where randomly initialized), so we want to be careful of not destroying the carefully tuned weights that are already there.\n",
    "\n",
    "Generally speaking, the earlier layers (as we've seen) have more general-purpose features. Therefore we would expect them to need less fine-tuning for new datasets. For this reason we will use different learning rates for different layers: the first few layers will be at 1e-4, the middle layers at 1e-3, and our FC layers we'll leave at 1e-2 as before. We refer to this as differential learning rates, although there's no standard name for this techique in the literature that we're aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=np.array([1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another trick we've used here is adding the cycle_mult parameter. Take a look at the following chart, and see if you can figure out what the parameter is doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that's what being plotted above is the learning rate of the final layers. The learning rates of the earlier layers are fixed at the same multiples of the final layer rates as we initially requested (i.e. the first layers have 100x smaller, and middle layers 10x smaller learning rates, since we set lr=np.array([1e-4,1e-3,1e-2])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('224_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('224_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is something else we can do with data augmentation: use it at inference time (also known as test time). Not surprisingly, this is known as test time augmentation, or just TTA.\n",
    "\n",
    "TTA simply makes predictions not just on the images in your validation set, but also makes predictions on a number of randomly augmented versions of them too (by default, it uses the original image along with 4 randomly augmented versions). It then takes the average prediction from these images, and uses that. To use TTA on the validation set, we can use the learner's TTA() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds,y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_np(probs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generally see about a 10-20% reduction in error on this dataset when using TTA at this point, which is an amazing result for such a quick and easy technique!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "A common way to analyze the result of a classification model is to use a confusion matrix. Scikit-learn has a convenient function we can use for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction\n",
    "preds = np.argmax(probs, axis=1)\n",
    "probs = probs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the prediction and y\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the prediction\n",
    "plot_val_with_title(most_by_correct(0, False), \"Most incorrect cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), \"Most incorrect dogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumarize Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick steps to train a world-class image classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. precompute=True\n",
    "2. Use lr_find() to find highest learning rate where loss is still clearly improving\n",
    "3. Train last layer from precomputed activations for 1-2 epochs\n",
    "4. Train last layer with data augmentation (i.e. precompute=False) for 2-3 epochs with cycle_len=1\n",
    "5. Unfreeze all layers\n",
    "6. Set earlier layers to 3x-10x lower learning rate than next higher layer\n",
    "7. Use lr_find() again\n",
    "8. Train full network with cycle_mult=2 until over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the key codes of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfms stands for transformations. \n",
    "# tfms_from_model takes care of resizing, image cropping, initial normalization (creating data with (mean,stdev) of (0,1)), and more.\n",
    "tfms = tfms_from_model(resnet34, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a path that points to the dataset. \n",
    "# In this path we will also store temporary data and final results. \n",
    "# ImageClassifierData.from_names_and_array takes in the names of the image files as well as an array of ground-truth labels and creates a dataset ready for training.\n",
    "data = ImageClassifierData.from_names_and_array(\n",
    "    path=PATH, \n",
    "    fnames=fnames, \n",
    "    y=labels, \n",
    "    classes=['dogs', 'cats'], \n",
    "    test_name='test', \n",
    "    tfms=tfms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvLearner.pretrained builds learner that contains a pre-trained model. \n",
    "# The last layer of the model needs to be replaced with the layer of the right dimensions. \n",
    "# The pretained model was trained for 1000 classes therfore the final layer predicts a vector of 1000 probabilities. \n",
    "# The model for cats and dogs needs to output a two dimensional vector. \n",
    "# The diagram below shows in an example how this was done in one of the earliest successful CNNs. \n",
    "# The layer \"FC8\" here would get replaced with a new layer with 2 outputs.\n",
    "learn = ConvLearner.pretrained(resnet34, data, precompute=True, tmp_name=TMP_PATH, models_name=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are learned by fitting a model to the data. Hyperparameters are another kind of parameter, that cannot be directly learned from the regular training process. These parameters express higher-level properties of the model such as its complexity or how fast it should learn. Two examples of hyperparameters are the learning rate and the number of epochs.\n",
    "\n",
    "During iterative training of a neural network, a batch or mini-batch is a subset of training samples used in one iteration of Stochastic Gradient Descent (SGD). An epoch is a single pass through the entire training set which consists of multiple iterations of SGD.\n",
    "\n",
    "We can now fit the model; that is, use gradient descent to find the best parameters for the fully connected layer we added, that can separate cat pictures from dog pictures. We need to pass two hyperameters: the learning rate (generally 1e-2 or 1e-3 is a good starting point, we'll look more at this next) and the number of epochs (you can pass in a higher number and just stop training when you see it's no longer improving, then re-run it with the number of epochs you found works well.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing loss and accuracy of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run learn.fit we print 3 performance values (see above.) Here 0.03 is the value of the loss in the training set, 0.0226 is the value of the loss in the validation set and 0.9927 is the validation accuracy. What is the loss? What is accuracy? Why not to just show accuracy?\n",
    "\n",
    "Accuracy is the ratio of correct prediction to the total number of predictions.\n",
    "\n",
    "In machine learning the loss function or cost function is representing the price paid for inaccuracy of predictions.\n",
    "\n",
    "The loss associated with one example in binary classification is given by: -(y * log(p) + (1-y) * log (1-p)) where y is the true label of x and p is the probability predicted by our model that the label is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(y, p):\n",
    "    return np.mean(-(y * np.log(p) + (1-y)*np.log(1-p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = np.array([1, 0, 0, 1])\n",
    "preds = np.array([0.9, 0.1, 0.2, 0.8])\n",
    "binary_loss(acts, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in our toy example above our accuracy is 100% and our loss is 0.16. Compare that to a loss of 0.03 that we are getting while predicting cats and dogs. Exercise: play with preds to get a lower loss for this example.\n",
    "\n",
    "Example: Here is an example on how to compute the loss for one example of binary classification problem. Suppose for an image x with label 1 and your model gives it a prediction of 0.9. For this case the loss should be small because our model is predicting a label  1  with high probability.\n",
    "\n",
    "loss = -log(0.9) = 0.10\n",
    "\n",
    "Now suppose x has label 0 but our model is predicting 0.9. In this case our loss should be much larger.\n",
    "\n",
    "loss = -log(1-0.9) = 2.30\n",
    "\n",
    "Exercise: look at the other cases and convince yourself that this make sense.\n",
    "Exercise: how would you rewrite binary_loss using if instead of * and +?\n",
    "Why not just maximize accuracy? The binary classification loss is an easier function to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
